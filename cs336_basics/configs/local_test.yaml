dataset:
  train_dataset_path: "/Users/waihongong/github/assignment1-basics/data/TinyStoriesTrain_10k/TinyStoriesV2-GPT4-valid.tok.npy"
  valid_dataset_path: "/Users/waihongong/github/assignment1-basics/data/TinyStoriesTrain_10k/TinyStoriesV2-GPT4-valid.tok.npy"
  vocab_path: "/Users/waihongong/github/assignment1-basics/data/TinyStoriesTrain_10k/vocab.json"
  merges_path: "/Users/waihongong/github/assignment1-basics/data/TinyStoriesTrain_10k/merges.txt"
device: "mps"
ckpt_dir: "checkpoints"
ckpt_every: 20
training:
  num_tokens: 300000
  valid_num_tokens: 3270
  batch_size: 32
  context_length: 100
model:
  num_heads: 4
  d_head: 32
  d_ff: 384
opt:
  max_lr: 1e-3
  min_lr: 1e-4
  warmup_iters: 10